setwd("~/Documents/Master_Y1_B1/course-dataprep/Tutorials/Tutorial3_version_ control")
git clone https://github.com/SanneWielders/version-control-exersices.git
ls
setwd("~/Documents/Master_Y1_B1/course-dataprep/Tutorials/Tutorial3_version_ control/version-control-exersices")
git status
setwd("~/Documents/Master_Y1_B1/course-dataprep/Tutorials/Tutorial3_version_ control/version-control-exersices")
setwd("~/Documents/Master_Y1_B1/course-dataprep/Tutorials/Tutorial3_version_control/version-control-exersices")
getwd()
setwd("~/Documents/Master_Y1_B1/course-dataprep/Tutorials/Tutorial3_version_ control/version-control-exersices")
git status
library(haven)
adoption <- read_sav("~/Documents/Master_Y1_B1/Intro to research in marketing/Week 5/adoption.sav")
View(adoption)
summary(adoption)
adoption_glm1 <- glm(adopter ~ ., adoption[, 3:16], family=binomial); summary(adoption_glm1)
exp(adoption_glm1$coef)
View(adoption_glm1)
View(adoption_glm1)
exp(adoption_glm1$coef)
View(adoption)
exp(adoption_glm1$coef)
install.packages("lmtest")
library(lmtest)
adoption_glm0 <- glm(adopter ~ 1, adoption[,3:16], family=binomial)
lrtest(adoption_glm1, adoption_glm0)
install.packages("pscl")
library(pscl)
pR2(adoption_glm1) # r2ML = Cox & Snell R2
install.packages("QuantPsyc")
library(QuantPsyc)
adoption_glm1_ct1 <- ClassLog(adoption_glm1, adoption$adopter, cut=.5) # left: predicted, top: observed
t(adoption_glm1_ct1$rawtab) # transpose such that left: observed, top: predicted, as in lecture
adoption_glm1_ct2 <- ClassLog(adoption_glm1, adoption$adopter, cut=mean(adoption$adopter)) # left: predicted, top: observed
t(adoption_glm1_ct2$rawtab) # transpose such that left: observed, top: predicted, as in lecture
# Hosmer Lemeshow test
install.packages("ResourceSelection")
library(ResourceSelection)
adoption_glm1_hl <- hoslem.test(adoption_glm1$y, adoption_glm1$fitted.values, g=10)
adoption_glm1_hl
cbind(adoption_glm1_hl$observed, adoption_glm1_hl$expected)
# 1) Restrict to current customers
adopt_cc <- subset(adoption, sow_before > 0)
# 2) Start from the same explanatory set as in the tutorial (cols 3:16),
#    then: drop sow_before & tripsleclerc_before, replace nr_hmsm_lecl with SOF.
base_cols <- names(adoption)[3:16]
# be tolerant to the possible misspelling "nr_hmsm_lec"
drop_vars <- c("sow_before", "tripsleclerc_before", "nr_hmsm_lecl", "nr_hmsm_lec")
preds <- setdiff(base_cols, c("adopter", drop_vars))
preds <- union(preds, "SOF")
form_q1 <- as.formula(paste("adopter ~", paste(preds, collapse = " + ")))
fit_q1  <- glm(form_q1, data = adopt_cc, family = binomial)
stopifnot("age" %in% names(adopt_cc))
# 3) Compute odds change for age being 1 SD below mean vs at mean
#    In logistic regression, a change Δx multiplies the odds by exp(beta * Δx).
#    Here Δx = -sd(age) (one SD *below* the mean).
stopifnot("age" %in% names(adopt_cc))
beta_age <- coef(fit_q1)["age"]
# 1) Restrict to current customers
adopt_cc <- subset(adoption, sow_before > 0)
# 2) Start from the same explanatory set as in the tutorial (cols 3:16),
#    then: drop sow_before & tripsleclerc_before, replace nr_hmsm_lecl with SOF.
base_cols <- names(adoption)[3:16]
# be tolerant to the possible misspelling "nr_hmsm_lec"
drop_vars <- c("sow_before", "tripsleclerc_before", "nr_hmsm_lecl", "nr_hmsm_lec")
# predictors from 3:16 minus drops, plus SOF
preds <- setdiff(base_cols, c("adopter", drop_vars))
preds <- union(preds, "SOF")
# Build formula and fit on the subset
form_q1 <- as.formula(paste("adopter ~", paste(preds, collapse = " + ")))
fit_q1  <- glm(form_q1, data = adopt_cc, family = binomial)
# 3) Compute odds change for age being 1 SD below mean vs at mean
#    In logistic regression, a change Δx multiplies the odds by exp(beta * Δx).
#    Here Δx = -sd(age) (one SD *below* the mean).
stopifnot("age" %in% names(adopt_cc))
## Q1: Redo model per instructions and compute 1-SD age effect
# 1) Restrict to current customers
adopt_cc <- subset(adoption, sow_before > 0)
# 2) Start from the same explanatory set as in the tutorial (cols 3:16),
#    then: drop sow_before & tripsleclerc_before, replace nr_hmsm_lecl with SOF.
base_cols <- names(adoption)[3:16]
# be tolerant to the possible misspelling "nr_hmsm_lec"
drop_vars <- c("sow_before", "tripsleclerc_before", "nr_hmsm_lecl", "nr_hmsm_lec")
# predictors from 3:16 minus drops, plus SOF
preds <- setdiff(base_cols, c("adopter", drop_vars))
preds <- union(preds, "SOF")
# Build formula and fit on the subset
form_q1 <- as.formula(paste("adopter ~", paste(preds, collapse = " + ")))
fit_q1  <- glm(form_q1, data = adopt_cc, family = binomial)
# 3) Compute odds change for age being 1 SD below mean vs at mean
#    In logistic regression, a change Δx multiplies the odds by exp(beta * Δx).
#    Here Δx = -sd(age) (one SD *below* the mean).
stopifnot("age" %in% names(adopt_cc))
## --- Q1: redo model + compute 1-SD age effect (robust to column names) ---
# 1) Subset to current customers
stopifnot("sow_before" %in% names(adoption))
adopt_cc <- subset(adoption, sow_before > 0)
# 2) Define base set from tutorial (cols 3:16), then edit per instructions
base_cols <- names(adoption)[3:16]
# drops and DV
drop_vars <- c("sow_before", "tripsleclerc_before", "nr_hmsm_lecl", "nr_hmsm_lec", "adopter")
# find SOF (case-insensitive)
sof_candidates <- names(adoption)[tolower(names(adoption)) == "sof"]
if (length(sof_candidates) == 0) {
sof_candidates <- names(adoption)[grepl("^sof$", names(adoption), ignore.case = TRUE)]
}
stopifnot("Couldn't find SOF in your data. Make sure a column named 'SOF' exists (any case)." =
length(sof_candidates) >= 1)
sof_var <- sof_candidates[1]
# predictors = base minus drops, then ensure SOF is included
preds <- setdiff(base_cols, drop_vars)
preds <- union(preds, sof_var)
# Build formula and fit
stopifnot("adopter" %in% names(adopt_cc))
form_q1 <- as.formula(paste("adopter ~", paste(preds, collapse = " + ")))
fit_q1  <- glm(form_q1, data = adopt_cc, family = binomial)
# 3) Find an age-like numeric column automatically
age_candidates <- names(adopt_cc)[grepl("age", names(adopt_cc), ignore.case = TRUE)]
age_candidates <- age_candidates[sapply(age_candidates, \(v) is.numeric(adopt_cc[[v]]))]
# Prefer common age names if multiple
prefer <- c("age","age_head","agehh","age_hh","agehshld","age_household","age_person","age_resp","age_respondent")
pick_prefer <- age_candidates[match(tolower(prefer), tolower(age_candidates), nomatch = 0)]
age_var <- if (length(pick_prefer) >= 1) pick_prefer[1] else if (length(age_candidates) >= 1) age_candidates[1] else NA
stopifnot("No numeric 'age' column found. Candidates were: " %+% paste(names(adopt_cc), collapse = ", ") = !is.na(age_var))
library(haven)
adoption <- read_sav("~/Documents/Master_Y1_B1/Intro to research in marketing/Week 5/adoption.sav")
View(adoption)
# 1) Subset to current customers
stopifnot("sow_before" %in% names(adoption))
adopt_cc <- subset(adoption, sow_before > 0)
# 2) Define base set from tutorial (cols 3:16), then edit per instructions
base_cols <- names(adoption)[3:16]
# drops and DV
drop_vars <- c("sow_before", "tripsleclerc_before", "nr_hmsm_lecl", "nr_hmsm_lec", "adopter")
sof_candidates <- names(adoption)[tolower(names(adoption)) == "sof"]
if (length(sof_candidates) == 0) {
sof_candidates <- names(adoption)[grepl("^sof$", names(adoption), ignore.case = TRUE)]
}
stopifnot("Couldn't find SOF in your data. Make sure a column named 'SOF' exists (any case)." =
length(sof_candidates) >= 1)
sof_var <- sof_candidates[1]
# predictors = base minus drops, then ensure SOF is included
preds <- setdiff(base_cols, drop_vars)
preds <- union(preds, sof_var)
stopifnot("adopter" %in% names(adopt_cc))
form_q1 <- as.formula(paste("adopter ~", paste(preds, collapse = " + ")))
fit_q1  <- glm(form_q1, data = adopt_cc, family = binomial)
age_candidates <- names(adopt_cc)[grepl("age", names(adopt_cc), ignore.case = TRUE)]
age_candidates <- age_candidates[sapply(age_candidates, \(v) is.numeric(adopt_cc[[v]]))]
prefer <- c("age","age_head","agehh","age_hh","agehshld","age_household","age_person","age_resp","age_respondent")
pick_prefer <- age_candidates[match(tolower(prefer), tolower(age_candidates), nomatch = 0)]
age_var <- if (length(pick_prefer) >= 1) pick_prefer[1] else if (length(age_candidates) >= 1) age_candidates[1] else NA
stopifnot("No numeric 'age' column found. Candidates were: " %+% paste(names(adopt_cc), collapse = ", ") = !is.na(age_var))
library(haven)
library(lmtest)
library(pscl)
library(QuantPsyc)
library(ResourceSelection)
# 1) Keep only current customers
adopt_cc <- subset(adoption, sow_before > 0)
vars_3_16 <- names(adoption)[3:16]
vars_use  <- setdiff(vars_3_16, c("sow_before","tripsleclerc_before","nr_hmsm_lecl","nr_hmsm_lec"))
vars_use  <- union(vars_use, "SOF")  # ensure SOF is included
adopt_cc_model <- adopt_cc[, c("adopter", vars_use)]
# 3) Generalized linear model (logit), like in the tutorial
adoption_glm_q1 <- glm(adopter ~ ., adopt_cc_model, family = binomial)
summary(adoption_glm_q1)
# Odds ratios
exp(adoption_glm_q1$coef)
adoption_glm0_q1 <- glm(adopter ~ 1, adopt_cc_model, family = binomial)
lrtest(adoption_glm_q1, adoption_glm0_q1)
# 5) R² measures (Cox & Snell, Nagelkerke)
pR2(adoption_glm_q1)
adoption_glm_q1_ct1 <- ClassLog(adoption_glm_q1, adopt_cc$adopter, cut = .5)
t(adoption_glm_q1_ct1$rawtab)
base_rate <- mean(adopt_cc$adopter, na.rm = TRUE)
adoption_glm_q1_ct2 <- ClassLog(adoption_glm_q1, adopt_cc$adopter, cut = base_rate)
t(adoption_glm_q1_ct2$rawtab)
adoption_glm_q1_hl <- hoslem.test(adoption_glm_q1$y, adoption_glm_q1$fitted.values, g = 10)
adoption_glm_q1_hl
cbind(adoption_glm_q1_hl$observed, adoption_glm_q1_hl$expected)
beta_age <- adoption_glm_q1$coef["age"]
sd_age   <- sd(adopt_cc$age, na.rm = TRUE)
View(adoption_glm_q1)
odds_change_factor <- exp(beta_age * (-sd_age))
round(odds_change_factor, 3)
# --- Q1: Redo the analysis per instructions (tutorial style) ---
library(haven)
library(lmtest)
library(pscl)
library(QuantPsyc)
library(ResourceSelection)
# 0) Load data (adjust path if needed)
# adoption <- read_sav("~/Documents/Master_Y1_B1/Intro to research in marketing/Week 5/adoption.sav")
# 1) Keep only current customers
adopt_cc <- subset(adoption, sow_before > 0)
# 2) Build the modeling frame like in the tutorial, but with the requested changes
#    - start from columns 3:16
#    - drop sow_before and tripsleclerc_before
#    - replace nr_hmsm_lecl (or nr_hmsm_lec) with SOF
vars_3_16 <- names(adoption)[3:16]
vars_use  <- setdiff(vars_3_16, c("sow_before","tripsleclerc_before","nr_hmsm_lecl","nr_hmsm_lec"))
vars_use  <- union(vars_use, "SOF")  # ensure SOF is included
adopt_cc_model <- adopt_cc[, c("adopter", vars_use)]
# 3) Generalized linear model (logit), like in the tutorial
adoption_glm_q1 <- glm(adopter ~ ., adopt_cc_model, family = binomial)
summary(adoption_glm_q1)
# Odds ratios
exp(adoption_glm_q1$coef)
# 4) Log-likelihood ratio test (vs intercept-only)
adoption_glm0_q1 <- glm(adopter ~ 1, adopt_cc_model, family = binomial)
lrtest(adoption_glm_q1, adoption_glm0_q1)
# 5) R² measures (Cox & Snell, Nagelkerke)
pR2(adoption_glm_q1)
# 6) Classification tables (cut = .5 and cut = base rate)
adoption_glm_q1_ct1 <- ClassLog(adoption_glm_q1, adopt_cc$adopter, cut = .5)
t(adoption_glm_q1_ct1$rawtab)
base_rate <- mean(adopt_cc$adopter, na.rm = TRUE)
adoption_glm_q1_ct2 <- ClassLog(adoption_glm_q1, adopt_cc$adopter, cut = base_rate)
t(adoption_glm_q1_ct2$rawtab)
# 7) Hosmer–Lemeshow test
adoption_glm_q1_hl <- hoslem.test(adoption_glm_q1$y, adoption_glm_q1$fitted.values, g = 10)
adoption_glm_q1_hl
cbind(adoption_glm_q1_hl$observed, adoption_glm_q1_hl$expected)
# --- Q1 answer: odds change for age = mean - 1 SD vs mean ---
# (This is the multiplicative change in odds; report it rounded to 3 decimals, e.g., 1.243)
beta_age <- adoption_glm_q1$coef["age"]
sd_age   <- sd(adopt_cc$age, na.rm = TRUE)
odds_change_factor <- exp(beta_age * (-sd_age))
round(odds_change_factor, 3)
variable.names(adoption)
library(haven)
adoption <- read_sav("~/Documents/Master_Y1_B1/Intro to research in marketing/Week 5/adoption.sav")
View(adoption)
library(haven)
library(lmtest)
library(pscl)
library(QuantPsyc)
library(ResourceSelection)
# 0) Load data if not already loaded
# adoption <- read_sav("~/Documents/Master_Y1_B1/Intro to research in marketing/Week 5/adoption.sav")
# 1) Keep only current customers
adopt_cc <- subset(adoption, sow_before > 0)
library(haven)
library(lmtest)
library(pscl)
library(QuantPsyc)
library(ResourceSelection)
# 0) Load data if not already loaded
# adoption <- read_sav("~/Documents/Master_Y1_B1/Intro to research in marketing/Week 5/adoption.sav")
# 1) Keep only current customers
adopt_cc <- subset(adoption, sow_before > 0)
# 2) Use the same explanatory variables as in the tutorial (cols 3:16),
#    but now (i) replace nr_hmsm_lec with SOF, (ii) drop sow_before & tripsleclerc_before
# Columns 3:16 are: adopter, microzone_type, NearStore, DistDrive_BM, numdrives, Age, HHS,
# tripsleclerc_before, sow_before, ltotalspent, ltotalspent_internet, nr_hmsm_lec, nr_hmsm_comp, nr_compdrives
adopt_cc_model <- adopt_cc[, c(
"adopter",
"microzone_type","NearStore","DistDrive_BM","numdrives","Age","HHS",
"ltotalspent","ltotalspent_internet",    # (dropped tripsleclerc_before & sow_before)
"SOF",                                   # (replaces nr_hmsm_lec)
"nr_hmsm_comp","nr_compdrives"
)]
# 3) Logistic regression, like in the tutorial
adoption_glm_q1 <- glm(adopter ~ ., adopt_cc_model, family = binomial); summary(adoption_glm_q1)
exp(adoption_glm_q1$coef)
# (Optional, to mirror the tutorial completely)
adoption_glm0_q1 <- glm(adopter ~ 1, adopt_cc_model, family = binomial)
lrtest(adoption_glm_q1, adoption_glm0_q1)
pR2(adoption_glm_q1)
adoption_glm_q1_ct1 <- ClassLog(adoption_glm_q1, adopt_cc$adopter, cut = .5)
t(adoption_glm_q1_ct1$rawtab)
base_rate <- mean(adopt_cc$adopter, na.rm = TRUE)
adoption_glm_q1_ct2 <- ClassLog(adoption_glm_q1, adopt_cc$adopter, cut = base_rate)
t(adoption_glm_q1_ct2$rawtab)
adoption_glm_q1_hl <- hoslem.test(adoption_glm_q1$y, adoption_glm_q1$fitted.values, g = 10)
adoption_glm_q1_hl
cbind(adoption_glm_q1_hl$observed, adoption_glm_q1_hl$expected)
beta_age <- adoption_glm_q1$coef["Age"]
sd_age   <- sd(adopt_cc$Age, na.rm = TRUE)
odds_change_factor <- exp(beta_age * (-sd_age))
# Submit THIS number (rounded to 3 decimals), e.g., 1.243
round(odds_change_factor, 3)
# (Optional) percent change in odds for your own interpretation:
round((odds_change_factor - 1) * 100, 1)
p_near <- 0.045
b_near <- coef(adoption_glm_q1)["NearStore"]   # = -0.24349 in your summary
p_stand <- plogis(qlogis(p_near) - b_near)
round(p_stand, 3)   # 0.057
summary(adoption_glm_q1)
round(-0.2434933, 3)
p_near <- 0.045
or_near <- exp(coef(adoption_glm_q1)["NearStore"])  # odds ratio for NearStore (vs standalone)
odds_near  <- p_near / (1 - p_near)
odds_stand <- odds_near / or_near                    # switch from NearStore=1 to 0
p_stand    <- odds_stand / (1 + odds_stand)
round(p_stand, 3)
# 8% cutoff
adoption_glm_q1_ct8 <- ClassLog(adoption_glm_q1, adopt_cc$adopter, cut = 0.08)
cm_8 <- t(adoption_glm_q1_ct8$rawtab)  # rows = observed, cols = predicted (as in lecture)
cm_8
# Accuracy (%) rounded to 1 decimal
acc_8 <- sum(diag(cm_8)) / sum(cm_8) * 100
round(acc_8, 1)
p_hat <- predict(adoption_glm_q1, type = "response")
pred8 <- as.integer(p_hat >= 0.08)
tab8 <- table(obs = adopt_cc$adopter, pred = pred8)
acc8 <- sum(diag(tab8)) / sum(tab8) * 100
round(acc8, 1)
# Predicted probabilities from your Q1 model
p_hat <- predict(adoption_glm_q1, type = "response")
# Size of top decile (exact 10% of the scored sample)
N <- length(p_hat)
k <- max(1, floor(0.10 * N))
# Indices of the highest-k probabilities
ord <- order(p_hat, decreasing = TRUE)
top_idx <- ord[seq_len(k)]
# Response (adoption) rates
base_rate <- mean(adopt_cc$adopter, na.rm = TRUE)
top_rate  <- mean(adopt_cc$adopter[top_idx], na.rm = TRUE)
# Top decile lift
tdl <- top_rate / base_rate
round(tdl, 3)
round(c(base_rate = base_rate, top_rate = top_rate), 4)
